---
layout:     post                    # 使用的布局（不需要改）
title:      MLDS18-GAN-General framework of GAN (fGAN)  # 标题 
subtitle:   Lecture-03              #副标题
date:       2019-06-03              # 时间
author:     ChillyRain      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - GAN
---

## f-divergence

f-divergence是评估两个概率分布距离的通用框架，上一篇提到的MMGAN中使用的JSD是其中的一个特例。

给定两个概率分布P和Q，二者间的f-divergence定义如下：

$$D_f(P||Q) = \int_{x} q(x) f(\frac{p(x)}{q(x)}) \,dx$$

其中，f为凸函数，$f(1) = 0$。可以证明，当P和Q为完全相同的概率分布时，$D_f = 0$且为$D_f$的最小值。

![proof](/img/post-GAN-fdiv-proof.png){:height="75%" width="75%"}

既然是一个通用框架，那么取不同的$f$就可以对应不同的评估P和Q距离的测度

![instance](/img/post-GAN-fdiv-instance.png){:height="75%" width="75%"}


## Fenchel Conjugate

任意一个凸函数$f$都有一个与之对应的函数，称为Fenchel Conjugate，其定义如下

![fcFig](/img/post-GAN-fdiv-fc.png){:height="75%" width="75%"}

$f^{\*}(t)$有以下两个性质
1. $f^{\*}$也是凸函数
2. $(f^{\*})^{\*} = f$


## Connection to GAN

利用Fenchenl Conjugate的第二个性质，将$f$表示为$f^{\*}$的表达式，并代入f-divergence的定义中可得

![inference](/img/post-GAN-fdiv-inference.png){:height="75%" width="75%"}

原JSD替换成任意的f-divergence代入GAN的框架中，最终的形式也与原始的GAN类似。

![connect](/img/post-GAN-fdiv-connect.png){:height="75%" width="75%"}


最后，GAN有mode collapse/dropping问题，即生成样本的多样性不足，用不同的f-divergence并不能解决这个问题。课程里给出的方案是多训几个不同的Generator，每个模型输出几个凑在一起就行。



