---
layout:     post                    # 使用的布局（不需要改）
title:      MLDS18-GAN-Theory Behind GAN # 标题 
subtitle:   Lecture-02 #副标题
date:       2019-06-03              # 时间
author:     ChillyRain      # 作者
header-img: img/post-bg-2015.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - GAN
---

如上一篇如述，GAN这种生成模型比较容易从中采样，但是在给定一个样本的情况下计算它的概率就比较困难了。一般的生成模型都是使用MLE来训练（MLE等价于模型对应的分布与真实分布之间的KL），GAN的这种特性就让它无法采取同样的训练策略了。但是训练目标是不变的，我们希望得到的模型对应的分布$P_G$与真实分布$P_{data}$之间的距离越近越好。

最初的GAN的论文(Goodfellow, et al., NIPS, 2014)中，作者采用的是JSD做为评测两个分布之间距离的测度。但是由于我们不知道$P_G$与$P_{data}$中的任何一个分布的解析形式，这个JSD也是没办法直接算的。相反，通过使用Discriminator作为中介（此处采用的是二分类器），并结合从两个分布上得到的样本（$P_G$的样本来真实图片集，而$P_{data}$的样本则是可以从先验分布上采样再由Generator生成）来近似得到这个值。

设计训练的目标函数为

$$
V(G, D) = E_{x \sim P_{data}}[logD(x)] + E_{x \sim P_G}[log(1-D(x))]
$$

对于给定的G，那么$max_D{V(G, D)}$的值就是JSD的近似值。证明如下：

$$V(G, D) = \int_x P_{data}(x)logD(x) \,dx + \int_x P_G(x)log(1-D(x)) \,dx$$

$$= \int_x [P_{data}(x)logD(x) + P_G(x)log(1-D(x))] \,dx$$

其中D是任意函数。此时希望能取合适D来最大化$V$的值，而$x$之间又是相互独立的，因此可以把整体的优化问题分解为对逐个$x$对应的$P_{data}(x)logD(x) + P_G(x)log(1-D(x))$进行最大化。此时的变量只有$D(x)$，因此可以看作对 $f(D) = alogD + blog(1-D)$的最大化问题，通过微分可得最优的$D^{*}(x)$为

$$
D^{*}(x) = \frac {P_{data}(x)}{P_{data}(x) + P_G(x)}
$$

将上式$D^{*}$代入原$V(G, D)$可得

$$max_D{V(G, D)} = V(G, D^{*})$$

$$= \int_x P_{data}(x) \frac {P_{data}(x)}{P_{data}(x) + P_G(x)} \,dx + \int_x P_G(x) \frac {P_G(x)}{P_{data}(x) + P_G(x)} \,dx $$

$$=-2log2 + KL(P_{data} || \frac{P_{data} + P_G}{2}) + KL(P_G || \frac{P_{data} + P_G}{2})$$

$$=-2log2 + JSD(P_{data} || P_G)$$

因此，对于任意给定的G，可以通过找到对应的最优的$D$来计算$V(G, D^{*})$，以此来评测这个G对应的$P_G$与$P_{data}$之间的JSD，并可以以此作为loss来驱动训练。实现中，最优化都是通过SGD来达到的，而计算V时对两个分布计算期望的操作则是由样本平均来代替。

![minmax](/img/post-GAN-minmax.png){:height="75%" width="75%"}

这也间接定义了整个训练的基本(粗糙)流程：先初始化一个G，通过采样生成一批负样本，再结合正样本来训练并找到最优的D，这个JSD此时反过来做为G训练的动力，调整G的参数使JSD变小，在得到了新的G之后再采一批负样本反过来训练新的D，周而复始，直至收敛为止。

以上流程实际是有问题的，给定$G_1$找最优的$D_1$固然是正确的，此时JSD为$V(G_1, D^{\*}_1)$，但是下一步在优化(最小化，找JSD最小的G)得到$G_2$时，得到是$V(G_2, D^{\*}_1)$，此时可以保证

$$V(G_2, D^{*}_1) <= V(G_1, D^{*}_1) = JSD_1$$

而在进一步优化D(最大化，找使V最大的D才能逼近JSD)得到的$JSD_2$却不一定比$JSD_1$要小，所以理论上并不通。

$$JSD_2 = V(G_2, D^{*}_2) >= V(G_2, D^{*}_1)$$

只能在更新G的时候不要更新幅度太大，从而可以假设对应的$D_1^{\*}$和$D_2^{\*}$差别不大，理论上使$P_G$单调地逼近真实分布$P_{data}$。

![pitfalls](/img/post-GAN-pitfalls.png){:height="75%" width="75%"}

最后是原始GAN的算法流程细节，以及对目标函数的一个变形

![algo](/img/post-GAN-MMGAN.png){:height="75%" width="75%"}

![nsgan](/img/post-GAN-NSGAN.png){:height="75%" width="75%"}





